{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a615766-e0ab-43fd-a4bc-e9937f758a77",
   "metadata": {},
   "source": [
    "# Building classification model on CIFAR-10 multiclass dataset\n",
    "It is based on the convolutional neural network implemented with PyTorch API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "acca56c4-d04d-4702-8db5-d149e13c0cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd6a238-d412-4976-8da3-37f44f4f45d7",
   "metadata": {},
   "source": [
    "## Device configuration and defining hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b99822e9-7bfa-434a-99c4-c95847676972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am using GPU acceleration :)\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 10\n",
    "batch_size = 40\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb190937-af4b-4bdc-be9d-4f75bb6356f4",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eaecdcc5-70a9-44b4-83a4-e5b5f7fd443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1e0794d8-8a78-4a02-8c14-f0c4f414433d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9ddb234c-fc87-4096-8605-2ce1596323c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cd91a663-fa73-4c92-a348-9355f005407f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "           )"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4f0987ce-c127-4712-a64b-0402cce3a41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "           )"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "770eaeee-ab27-44e9-a2b4-fee0c1d34921",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "18771a49-b46d-4f88-96d4-4c05e02acc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "44dbdaac-0525-4b1a-a247-f2df2544ef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e23dea-a495-49f5-8684-35b1d0cfc947",
   "metadata": {},
   "source": [
    "## Building CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3a4115f9-9711-4207-b1d7-a39f3ad7947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) #(in_channels, out_channels, kernel_size)\n",
    "        self.pool = nn.MaxPool2d(2, 2) #\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b2ed1b7b-b599-490c-a225-7a6ddc9ae026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model instantiation\n",
    "model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c35b12ff-f308-4501-94ea-5d7bab4b1f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Setting optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d98654-1efe-4881-96b7-49d9809b05df",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e1d4a736-1fea-43e8-8064-08fadb7e8ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Step: 500/1250, Loss: 1.6062\n",
      "Epoch: 1/10, Step: 1000/1250, Loss: 1.3311\n",
      "Epoch: 2/10, Step: 500/1250, Loss: 1.5644\n",
      "Epoch: 2/10, Step: 1000/1250, Loss: 1.1216\n",
      "Epoch: 3/10, Step: 500/1250, Loss: 1.3293\n",
      "Epoch: 3/10, Step: 1000/1250, Loss: 1.4173\n",
      "Epoch: 4/10, Step: 500/1250, Loss: 1.0742\n",
      "Epoch: 4/10, Step: 1000/1250, Loss: 1.3378\n",
      "Epoch: 5/10, Step: 500/1250, Loss: 1.0384\n",
      "Epoch: 5/10, Step: 1000/1250, Loss: 1.1379\n",
      "Epoch: 6/10, Step: 500/1250, Loss: 1.3039\n",
      "Epoch: 6/10, Step: 1000/1250, Loss: 0.9081\n",
      "Epoch: 7/10, Step: 500/1250, Loss: 1.0259\n",
      "Epoch: 7/10, Step: 1000/1250, Loss: 0.8653\n",
      "Epoch: 8/10, Step: 500/1250, Loss: 1.0190\n",
      "Epoch: 8/10, Step: 1000/1250, Loss: 1.0630\n",
      "Epoch: 9/10, Step: 500/1250, Loss: 0.4741\n",
      "Epoch: 9/10, Step: 1000/1250, Loss: 0.8329\n",
      "Epoch: 10/10, Step: 500/1250, Loss: 1.1568\n",
      "Epoch: 10/10, Step: 1000/1250, Loss: 0.9841\n",
      "Training Finished. Hurraay!\n"
     ]
    }
   ],
   "source": [
    "n_total_steps = len(train_loader) # number of training mini-batches\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # mini-batch is sent to the device \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 500 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Step: {i+1}/{n_total_steps}, Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Training Finished. Hurraay!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adc88fb-c3b0-4106-802d-bd925457c255",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fd4ec9a5-cf11-4d9c-b96f-d9cb1f085c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 63.67%\n",
      "Accuracy of plane: 71.1%\n",
      "Accuracy of car: 82.4%\n",
      "Accuracy of bird: 55.9%\n",
      "Accuracy of cat: 43.6%\n",
      "Accuracy of deer: 56.7%\n",
      "Accuracy of dog: 38.1%\n",
      "Accuracy of frog: 73.1%\n",
      "Accuracy of horse: 75.3%\n",
      "Accuracy of ship: 72.4%\n",
      "Accuracy of truck: 68.1%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "        \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc}%')\n",
    "    \n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc}%')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db8f5fd-02fc-42b2-ae72-cd607dc03334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
